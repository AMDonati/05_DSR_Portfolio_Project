{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REFERENCES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTEBOOKS - classic ML\n",
    "* [DSR- Gerrit- intro to ML] (http://localhost:8889/notebooks/00_TRAINING/02_DSR/05_ML_Geritt_Week2/Machine%20Learning%20-%20DSR%20Intro.ipynb)\n",
    "* [DSR-Gerrit- Boosting & XGBoost]\n",
    "http://localhost:8889/notebooks/00_TRAINING/02_DSR/05_ML_Geritt_Week2/Boosting%20and%20XGBoost.ipynb\n",
    "* [DSR-Gerrit- RF]\n",
    "(http://localhost:8889/notebooks/00_TRAINING/02_DSR/05_ML_Geritt_Week2/%20RF%20notebooks/DecisionTrees_Intro.ipynb)\n",
    "* [DSR-Gerrit-Evaluation models] (http://localhost:8889/notebooks/00_TRAINING/02_DSR/05_ML_Geritt_Week2/exercises/Evaluation%20Solutions.ipynb)\n",
    "* [DSR-Gerrit- Bayesian Learning]\n",
    "(http://localhost:8889/notebooks/00_TRAINING/02_DSR/05_ML_Geritt_Week2/exercises/Bayesian%20Learning%20Solutions.ipynb)\n",
    "* [DSR-Rachel-ML Pipelines]\n",
    "(http://localhost:8889/notebooks/00_TRAINING/02_DSR/10_DSR_Model_Pipelines_Rachel/1.3%20Pipelines%20.ipynb)\n",
    "* [DSR-Adam-Python tricks]\n",
    "(http://localhost:8889/notebooks/00_TRAINING/02_DSR/07_RL_Adam_Week4/dsr_rl/practical/generic_lessons/python_tricks.ipynb)\n",
    "\n",
    "http://localhost:8889/edit/00_TRAINING/02_DSR/05_ML_Geritt_Week2/ML_Essential_Concepts_Add-Michigan-Notes.txt\n",
    "\n",
    "### GITHUB repos: \n",
    "* **Hands-On Machine Learning w/scikit-learn and TensorFlow book: https://github.com/AMDonati/handson-ml**\n",
    "* sci-kit learn: https://github.com/AMDonati/scikit-learn/tree/master/sklearn\n",
    "* https://github.com/AMDonati/data-science-ipython-notebooks\n",
    "* Data Science w/ Python handbook: https://github.com/AMDonati/PythonDataScienceHandbook\n",
    "\n",
    "* https://github.com/AMDonati/machine-learning-cheat-sheet\n",
    "\n",
    "### Specific to time-series: \n",
    "* https://github.com/ChadFulton/tsa-notebooks\n",
    "* https://github.com/maxim5/time-series-machine-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FRAMEWORK\n",
    "1. Data-processing\n",
    "2. Plotting the data\n",
    "3. Preparing the data for the ML algo:\n",
    "    * Dimensionality reduction? \n",
    "    * Standardization/ normalisation? \n",
    "    * split train/val/test\n",
    "    * do something special for the multi-label classification problem?\n",
    "4. Select and train the model\n",
    "5. Model Evaluation: \n",
    "    * Fine-tune the model\n",
    "    * Cross-validtion\n",
    "    * Metrics plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports & functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.parse\n",
    "from glob import glob\n",
    "import os\n",
    "import ntpath \n",
    "import zipfile\n",
    "\n",
    "#paths\n",
    "#PPMI_zippath='/Users/alicemartin/02_DSR_Project/parkinson-disease-project/data/PPMI-final-dataset-382018.zip'\n",
    "PPMI_path='/Users/alicemartin/02_DSR_Project/parkinson-disease-project/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models to train\n",
    "0. Persistence baseline\n",
    "1. RF regressor for features importance\n",
    "2. RF/ XGBoost for time-series prediction\n",
    "3. Linear model with sample weighted loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the use of RF as a features importance selector: \n",
    "* https://towardsdatascience.com/running-random-forests-inspect-the-feature-importances-with-this-code-2b00dd72b92e\n",
    "* https://medium.com/the-artificial-impostor/feature-importance-measures-for-tree-models-part-i-47f187c1a2c3\n",
    "* https://chrisalbon.com/machine_learning/trees_and_forests/feature_selection_using_random_forest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a random forest on the 2 possible labels (NHY & MODEADL)\n",
    "### Take different targets values to see how it evolves. \n",
    "### Take also all samples with the mean. \n",
    "* DiagFeat\n",
    "* Non-Motor Assessments\n",
    "* Motor Assessments\n",
    "* General Medical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
